{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import os   \n",
    "import pandas as pd\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from cap_dataset import CascadeRegression\n",
    "from cap_model import GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_regression_ds = CascadeRegression(root=\"data\", name=\"facebook\", edge_index_path=\"data/raw/facebook/adj.txt\", task=\"regression\", observation=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(fb_regression_ds.num_features, 64, 1, 8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(fb_regression_ds)\n",
    "train_size = int(0.7 * total_size)\n",
    "valid_size = int(0.15 * total_size) \n",
    "test_size = total_size - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split (fb_regression_ds, [train_size, valid_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_loader.dataset[2].y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrse_loss(output, target):\n",
    "    # Check for zero to avoid division by zero\n",
    "    if target != 0:\n",
    "        loss = ((output - target) / target) ** 2\n",
    "    else:\n",
    "        # If target is zero, fallback to MSE to avoid NaN\n",
    "        loss = (output - target) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    total_loss = 0 \n",
    "    model.train()\n",
    "    print(len(loader))\n",
    "    for idx, data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        print(data.cascade_name)\n",
    "        print (out.shape)\n",
    "        print(out)\n",
    "        print(data.y.shape)\n",
    "        print(data.y)\n",
    "        print('\\n')\n",
    "        loss = F.mse_loss(out.squeeze().unsqueeze(0), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len (loader)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data)\n",
    "            loss = F.mse_loss(out, data.y.view(-1, 1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    train_loss = train(train_dataset)\n",
    "    valid_loss = test(valid_dataset)\n",
    "    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')\n",
    "\n",
    "test_loss = test(test_dataset)\n",
    "print(f'Test MSE Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reduce head to have better performance\n",
    "2. Run 100 epochs \n",
    "3. Use graph norm \n",
    "4. See how coupledgnn data is \n",
    "5. see if there is an issue with the y and the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
